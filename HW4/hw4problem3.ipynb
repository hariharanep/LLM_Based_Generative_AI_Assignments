{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj9UG72nneAJ"
   },
   "source": [
    "# Question 4: Implement ReAct Agent with Multiple Tools (25 points)\n",
    "\n",
    "Implement a ReAct (Reasoning and Acting) agent as described by Yao et al. [1], incorporating three main tools: search, compare, and analyze. This agent should be able to handle complex queries by reasoning about which tool to use and when.\n",
    "\n",
    "a) (4 points) Implement the search tool using the SerpAPI integration from previous questions. Ensure it can be easily used by the ReAct agent.\n",
    "   - Proper integration with SerpAPI\n",
    "   - Formatting the search results for use by the ReAct agent\n",
    "\n",
    "b) (5 points) Create a custom comparison tool using LangChain's `Tool` class. The tool should accept multiple items and a category as input and return a comparison result.\n",
    "   - Implementing the comparison logic\n",
    "   - Creating an appropriate prompt template for the comparison\n",
    "   - Proper error handling for invalid inputs\n",
    "\n",
    "c) (5 points) Implement an analysis tool that can summarize and extract key information from search results or comparisons. This tool should use the OpenAI model to generate insightful analyses.\n",
    "   - Implementing the analysis logic\n",
    "   - Creating an appropriate prompt template for the analysis\n",
    "   - Ensuring the analysis output is concise and relevant\n",
    "\n",
    "d) (6 points) Integrate these tools with a ReAct agent using LangChain. Your implementation should:\n",
    "   - Use LangChain's `initialize_agent` function with the `AgentType.ZERO_SHOT_REACT_DESCRIPTION` agent type\n",
    "   - Include all three tools (search, compare, analyze) as available actions for the agent\n",
    "   - Implement proper error handling and fallback strategies\n",
    "   - Ensure smooth transitions between tools in the agent's reasoning process\n",
    "\n",
    "e) (5 points) Implement a simple Streamlit user interface for your ReAct agent. Your implementation should include:\n",
    "   - A text input field for users to enter their queries\n",
    "   - A button to submit the query and trigger the ReAct agent\n",
    "   - A display area for showing the final results\n",
    "   - A section to display the step-by-step reasoning process of the ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-19T00:32:39.104553Z",
     "iopub.status.busy": "2025-11-19T00:32:39.104017Z",
     "iopub.status.idle": "2025-11-19T00:32:49.704677Z",
     "shell.execute_reply": "2025-11-19T00:32:49.703979Z",
     "shell.execute_reply.started": "2025-11-19T00:32:39.104523Z"
    },
    "id": "GYINe7f5o2ts",
    "outputId": "a663dc19-1767-4e6c-e334-ba4a1485019e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q \"langchain>=0.2.10\" \"langchain-openai>=0.2.10\" \"langchain-community>=0.2.10\" \"google-search-results\" \"streamlit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:14.536335Z",
     "iopub.status.busy": "2025-11-19T00:33:14.536050Z",
     "iopub.status.idle": "2025-11-19T00:33:24.512318Z",
     "shell.execute_reply": "2025-11-19T00:33:24.511481Z",
     "shell.execute_reply.started": "2025-11-19T00:33:14.536310Z"
    },
    "id": "UoG8eGynneAL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Set API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = '****************************************'\n",
    "os.environ[\"SERPAPI_API_KEY\"] = '****************************************'\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI language model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YsEDSkNneAM"
   },
   "source": [
    "## a) Implement the search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:28.600914Z",
     "iopub.status.busy": "2025-11-19T00:33:28.600050Z",
     "iopub.status.idle": "2025-11-19T00:33:28.609002Z",
     "shell.execute_reply": "2025-11-19T00:33:28.608208Z",
     "shell.execute_reply.started": "2025-11-19T00:33:28.600885Z"
    },
    "id": "hSqY-ZEkneAM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the search tool using SerpAPI\n",
    "search_tool = load_tools([\"serpapi\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxZgkYH5neAN"
   },
   "source": [
    "## b) Create a custom comparison tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:32.166142Z",
     "iopub.status.busy": "2025-11-19T00:33:32.165538Z",
     "iopub.status.idle": "2025-11-19T00:33:32.172758Z",
     "shell.execute_reply": "2025-11-19T00:33:32.172051Z",
     "shell.execute_reply.started": "2025-11-19T00:33:32.166113Z"
    },
    "id": "_GCQNo7nneAN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def compare_items(query: str) -> str:\n",
    "    # Extract items and category from the query\n",
    "    extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"\"\"Reason about the query and come up with at least two items to compare and the comparison category from this query.\n",
    "        Query: {query}\n",
    "        CRITICAL: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or code blocks.\n",
    "        Your response must be exactly in this format: {{\"items\": [\"item1\", \"item2\"], \"category\": \"category description\"}}\n",
    "        Rules:\n",
    "        - Return ONLY the JSON object, nothing else\n",
    "        - Do not use markdown code blocks (no ```)\n",
    "        - Do not add any text before or after the JSON\n",
    "        - Items should be in a list\n",
    "        - Category should be a short descriptive string\n",
    "\n",
    "        JSON:\"\"\"\n",
    "    )\n",
    "    \n",
    "    extraction_result = llm(extraction_prompt.format(query=query))\n",
    "    # Parse the result\n",
    "    try:\n",
    "        input_data = json.loads(extraction_result)\n",
    "        items = input_data.get(\"items\", [])\n",
    "        category = input_data.get(\"category\", \"\")\n",
    "    except json.JSONDecodeError:\n",
    "        return f\"Error: Could not parse query properly. Please specify items and category in the query clearly.\"\n",
    "\n",
    "    if not items or len(items) < 2:\n",
    "        return \"Error: Insufficient number of items found to compare\"\n",
    "    if not category:\n",
    "        return \"Error: Category not specified\"\n",
    "\n",
    "    # Run the comparison\n",
    "    comparison_prompt = PromptTemplate(\n",
    "        input_variables=[\"items\", \"category\", \"query\"],\n",
    "        template=\"\"\"You are an expert analyst. Compare the following items in the context of {category}.\n",
    "        Items to compare: {items}\n",
    "        Keep in mind that the ultimate goal is to generate information to answer the query: {query}\n",
    "        Provide a comprehensive comparison covering all the below listed points in detail:\n",
    "        1. Similarities between the items\n",
    "        2. Differences between the items\n",
    "        3. Strengths and weaknesses of each item\n",
    "        4. Summary recommendation or conclusion\n",
    "        \n",
    "        Be objective, detailed, and well-structured in your analysis.\"\"\"\n",
    "    )\n",
    "    items_str = \", \".join(items)\n",
    "    prompt = comparison_prompt.format(items=items_str, category=category, query=query)\n",
    "    result = llm(prompt)    \n",
    "    return result\n",
    "\n",
    "compare_tool = Tool(\n",
    "    name=\"Compare\",\n",
    "    func=compare_items,\n",
    "    description='Reason about the query, come up with multiple items and a specific category to describe the query, compare the items based on the context of the category. Input: User query'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtxoHqPZneAN"
   },
   "source": [
    "## c) Implement an analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:35.932357Z",
     "iopub.status.busy": "2025-11-19T00:33:35.931868Z",
     "iopub.status.idle": "2025-11-19T00:33:35.936917Z",
     "shell.execute_reply": "2025-11-19T00:33:35.936129Z",
     "shell.execute_reply.started": "2025-11-19T00:33:35.932332Z"
    },
    "id": "FUJPXpXGneAN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# New function to analyze search results and perform comparisons\n",
    "def analyze_results(results: str) -> str:\n",
    "    analysis_prompt = PromptTemplate(\n",
    "        input_variables=[\"results\"],\n",
    "        template=\"\"\"You are an expert data analyst. Analyze the following results and provide key insights to answer the user query.\n",
    "        Results to analyze:{results}\n",
    "        Keep in mind that the ultimate goal is to generate information to answer the user query\n",
    "        Provide a concise analysis including:\n",
    "        1. Main findings and key points\n",
    "        2. Important patterns or trends identified\n",
    "        3. Critical takeaways\n",
    "        4. Actionable insights or recommendations\n",
    "        Keep your analysis focused, relevant, and well-organized. Be concise but comprehensive.\"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = analysis_prompt.format(results=results)\n",
    "    result = llm(prompt)\n",
    "    return result\n",
    "\n",
    "analyze_tool = Tool(\n",
    "    name=\"Analyze\",\n",
    "    func=analyze_results,\n",
    "    description=\"Analyze information to extract insights, patterns, and conclusions. Input: results to analyze. Summarize the results, interpret comparisons, or extract key information.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV3D8WavneAN"
   },
   "source": [
    "## d) Integrate tools with a ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:39.031542Z",
     "iopub.status.busy": "2025-11-19T00:33:39.030864Z",
     "iopub.status.idle": "2025-11-19T00:33:39.036767Z",
     "shell.execute_reply": "2025-11-19T00:33:39.036080Z",
     "shell.execute_reply.started": "2025-11-19T00:33:39.031518Z"
    },
    "id": "9q1MuynIneAN",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/3543538376.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Integrate tools with ReAct agent\n",
    "all_tools = search_tool + [compare_tool, analyze_tool]\n",
    "agent = initialize_agent(\n",
    "    tools=all_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    early_stopping_method=\"generate\",\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:43.696750Z",
     "iopub.status.busy": "2025-11-19T00:33:43.696453Z",
     "iopub.status.idle": "2025-11-19T00:33:43.701234Z",
     "shell.execute_reply": "2025-11-19T00:33:43.700383Z",
     "shell.execute_reply.started": "2025-11-19T00:33:43.696726Z"
    },
    "id": "vkXwfEbxqaCA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_query(query: str, max_steps: int = 100) -> str:\n",
    "    try:\n",
    "        return agent({\"input\": query, \"max_iterations\": max_steps})[\"output\"]\n",
    "    except RecursionError:\n",
    "        return \"The query was too complex and exceeded the maximum number of steps. Please try a simpler query.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mEH_VAtneAN"
   },
   "source": [
    "## Test Your Implementation\n",
    "\n",
    "Use the cell below to test your implementation with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:33:47.769030Z",
     "iopub.status.busy": "2025-11-19T00:33:47.768511Z",
     "iopub.status.idle": "2025-11-19T00:34:01.634669Z",
     "shell.execute_reply": "2025-11-19T00:34:01.634037Z",
     "shell.execute_reply.started": "2025-11-19T00:33:47.769005Z"
    },
    "id": "Zr588QR3neAN",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/629042221.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return agent({\"input\": query, \"max_iterations\": max_steps})[\"output\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Search tool to find information about the top smartphones in 2023.\n",
      "Action: Search\n",
      "Action Input: \"Top smartphones 2023\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Smartphones 2023'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Compare tool to compare the top smartphones in terms of camera quality and battery life.\n",
      "Action: Compare\n",
      "Action Input: \"Smartphones 2023\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/4215994792.py:20: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  extraction_result = llm(extraction_prompt.format(query=query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "1. Similarities between Smartphones and 2023:\n",
      "- Both are related to technology and advancements in the digital world.\n",
      "- Both have a significant impact on our daily lives and are constantly evolving.\n",
      "- Both are constantly being improved and upgraded to meet the changing needs and demands of consumers.\n",
      "- Both have a wide range of features and capabilities that make them essential tools for communication, entertainment, and productivity.\n",
      "\n",
      "2. Differences between Smartphones and 2023:\n",
      "- Smartphones are physical devices, while 2023 is a specific point in time.\n",
      "- Smartphones are tangible products that can be purchased and used, while 2023 is a concept that represents the future.\n",
      "- Smartphones have a specific set of features and capabilities, while 2023 is open to interpretation and can bring about a variety of changes and advancements in technology.\n",
      "\n",
      "3. Strengths and weaknesses of Smartphones:\n",
      "- Strengths:\n",
      "  - Portability: Smartphones are small and lightweight, making them easy to carry around and use on the go.\n",
      "  - Connectivity: Smartphones allow us to stay connected with others through various means such as calls, texts, and social media.\n",
      "  - Multi-functionality: Smartphones have a wide range of features and capabilities, making them versatile tools for communication\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Analyze tool to extract key information and insights from the comparison.\n",
      "Action: Analyze\n",
      "Action Input: \"Comparison of top smartphones in 2023\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "1. Main findings and key points:\n",
      "- The top smartphones in 2023 are expected to be the iPhone 13, Samsung Galaxy S23, and Google Pixel 6.\n",
      "- These smartphones are expected to have advanced features such as 5G connectivity, improved cameras, and longer battery life.\n",
      "- The iPhone 13 is projected to have the highest sales, followed by the Samsung Galaxy S23 and Google Pixel 6.\n",
      "\n",
      "2. Important patterns or trends identified:\n",
      "- The top smartphones in 2023 are all from well-established brands with a strong reputation in the market.\n",
      "- The focus of these smartphones is on improving connectivity, camera quality, and battery life, indicating a growing demand for these features among consumers.\n",
      "- The projected sales of these smartphones suggest that there will be a high demand for them in the market.\n",
      "\n",
      "3. Critical takeaways:\n",
      "- The competition among smartphone brands is expected to be intense in 2023, with the top brands vying for the top spot.\n",
      "- Consumers are increasingly looking for advanced features in their smartphones, and brands need to keep up with these demands to stay competitive.\n",
      "- The success of these top smartphones will depend on their ability to deliver on their promised features and meet consumer expectations.\n",
      "\n",
      "4. Actionable insights or recommendations:\n",
      "-\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The top 3 smartphones in 2023 are expected to be the iPhone 13, Samsung Galaxy S23, and Google Pixel 6. They will have advanced features such as 5G connectivity, improved cameras, and longer battery life. The competition among smartphone brands will be intense, and brands need to focus on delivering on consumer demands for advanced features to stay competitive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The top 3 smartphones in 2023 are expected to be the iPhone 13, Samsung Galaxy S23, and Google Pixel 6. They will have advanced features such as 5G connectivity, improved cameras, and longer battery life. The competition among smartphone brands will be intense, and brands need to focus on delivering on consumer demands for advanced features to stay competitive.\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation\n",
    "sample_query = \"What are the top 3 smartphones in 2023, and how do they compare in terms of camera quality and battery life?\"\n",
    "\n",
    "result = process_query(sample_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:49:23.631876Z",
     "iopub.status.busy": "2025-11-19T00:49:23.631160Z",
     "iopub.status.idle": "2025-11-19T00:49:23.650185Z",
     "shell.execute_reply": "2025-11-19T00:49:23.649649Z",
     "shell.execute_reply.started": "2025-11-19T00:49:23.631831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 00:49:23.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.640 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-19 00:49:23.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"ReAct Agent\")\n",
    "    \n",
    "query = st.text_area(\n",
    "    \"Enter your query:\"\n",
    ")\n",
    "\n",
    "if st.button(\"Submit Query\"):\n",
    "    if query:\n",
    "        result = process_query(query)\n",
    "                           \n",
    "        st.subheader(\"Final Answer\")\n",
    "        st.write(result)\n",
    "    else:\n",
    "        st.warning(\"Please enter a query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T00:49:30.533985Z",
     "iopub.status.busy": "2025-11-19T00:49:30.533308Z",
     "iopub.status.idle": "2025-11-19T00:49:47.452339Z",
     "shell.execute_reply": "2025-11-19T00:49:47.451613Z",
     "shell.execute_reply.started": "2025-11-19T00:49:30.533962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.154.77.242:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rBaqdvLneAN"
   },
   "source": [
    "## Submission Requirements\n",
    "\n",
    "Please submit the following items as part of your solution:\n",
    "\n",
    "1. Your complete code implementation for the ReAct agent and its tools.\n",
    "2. A sample question that you used to test your tool (make it complex enough to demonstrate the use of multiple tools).\n",
    "3. The final answer provided by your ReAct agent for the sample question.\n",
    "4. The complete history traces of the ReAct agent for your sample question, showing its thought process, actions, and observations. Your traces should follow a format similar to this example:\n",
    "\n",
    "```\n",
    "Thought: I need to find information about top smartphones first\n",
    "Action: Search[top smartphones 2023]\n",
    "Observation: [Search results about top smartphones]\n",
    "Thought: Now I should compare the top two options\n",
    "Action: Compare[iPhone 14 Pro, Samsung Galaxy S23 Ultra, smartphones]\n",
    "Observation: [Comparison result]\n",
    "Thought: I should analyze this comparison for the user\n",
    "Action: Analyze[comparison result]\n",
    "Observation: [Analysis of the comparison]\n",
    "Final Answer: [Your agent's final response to the user's query]\n",
    "```\n",
    "\n",
    "Ensure that your submission clearly demonstrates the agent's ability to reason about which tool to use and how to interpret the results from each tool. Your history traces should show a logical flow of thoughts, actions, and observations, culminating in a final answer that addresses the initial query.\n",
    "\n",
    "**Note:** Ensure that your ReAct agent can seamlessly switch between these tools based on the task at hand. The agent should be able to reason about which tool to use next and how to interpret the results from each tool.\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). ReAct: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629. https://arxiv.org/pdf/2210.03629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UYLcPQ6qMCR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
